# gpu-datasheet
| Architecture | Name | GPU Memory | Memory Bandwidth | FP16/BF16 | FB8/INT8 | Datasheet |
| ----- | ----- | ----- | ----- | ----- | ----- | ----- |
| Ampere | A100 | 40 GB / 80 GB | 1.55 TB/s / 1.94 TB/s | 312 TFLOPS (FP16) | 624TOPS (INT8) | [Link](https://www.nvidia.com/content/dam/en-zz/Solutions/Data-Center/a100/pdf/nvidia-a100-datasheet-us-nvidia-1758950-r4-web.pdf) |
| Ampere | A10 | 24 GB | 600 GB/s | 125 TFLOPS (FP16) | 250 TOPS (INT8) | [Link](https://www.nvidia.com/content/dam/en-zz/Solutions/Data-Center/a10/pdf/a10-datasheet.pdf) |
| Ampere | A40 | 48 GB | 696 GB/s | 149.7 TFLOPS (BF16 / FP16) | 299.3 TFLOPS (INT8) | [Link](https://images.nvidia.cn/content/Solutions/data-center/a40/nvidia-a40-datasheet.pdf) |
| Hopper | H100 |  |  | 1979 TFLOPS (BF16 / FP16) | 3958 TFLOPS (FP8 / INT8) | [Link](https://resources.nvidia.com/en-us-tensor-core/nvidia-tensor-core-gpu-datasheet) |
| Hopper | H200 |  |  | 1979 TFLOPS (BF16 / FP16) | 3958 TFLOPS (FP8 / INT8) | [Link](https://resources.nvidia.com/en-us-data-center-overview-mc/en-us-data-center-overview/hpc-datasheet-sc23-h200) |
| Blackwell | B200 | 1.44 TB | 64 TB/s |  | 72 PFLOPS | [Link](https://resources.nvidia.com/en-us-dgx-systems/dgx-b200-datasheet) |
| Blackwell | GB200 | 13.5 TB |  | 360 PFLOPS (FP16) | 720 PFLOPS (FP8) | [Link](https://resources.nvidia.com/en-us-dgx-systems/dgx-superpod-gb200-datasheet) |
